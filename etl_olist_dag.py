import sys
import os
from datetime import datetime

from airflow import DAG
from airflow.operators.python import PythonOperator
from sqlalchemy import create_engine

# Asegura que se pueda importar desde tu carpeta src
sys.path.append("/opt/airflow/integrated_project/src")

from config import DATASET_ROOT_PATH, PUBLIC_HOLIDAYS_URL, SQLITE_BD_ABSOLUTE_PATH, get_csv_to_table_mapping
from extract import extract
from load import load
from transform import run_queries

DB_URL = f"sqlite:///{SQLITE_BD_ABSOLUTE_PATH}"

def extract_task(ti):
    print("ðŸš€ Iniciando tarea de extracciÃ³n...")
    print(f"ðŸ“‚ DATASET_ROOT_PATH: {DATASET_ROOT_PATH}")
    print(f"ðŸ”— PUBLIC_HOLIDAYS_URL: {PUBLIC_HOLIDAYS_URL}")

    try:
        mapping = get_csv_to_table_mapping()
        print(f"ðŸ“‘ CSV â†’ Tabla mapping: {mapping}")

        dataframes = extract(DATASET_ROOT_PATH, mapping, PUBLIC_HOLIDAYS_URL)
        print("âœ… ExtracciÃ³n completada. DataFrames extraÃ­dos:")
        for key, df in dataframes.items():
            print(f"ðŸ“„ {key}: {df.shape} filas")

        ti.xcom_push(key="dataframes", value=dataframes)
    except Exception as e:
        print(f"âŒ Error en extract_task: {e}")
        raise

def load_task(ti):
    print("ðŸšš Iniciando tarea de carga a la base de datos...")
    print(f"ðŸ”— Conectando a la base de datos: {DB_URL}")
    
    try:
        engine = create_engine(DB_URL)
        dataframes = ti.xcom_pull(task_ids="extract", key="dataframes")

        if not dataframes:
            print("âš ï¸ No se encontraron DataFrames en XCom.")
            raise ValueError("No se recibiÃ³ ningÃºn dataframe desde extract_task.")
        
        load(dataframes, engine)
        print("âœ… Carga completada exitosamente.")
    except Exception as e:
        print(f"âŒ Error en load_task: {e}")
        raise

def transform_task():
    print("ðŸ”§ Iniciando tarea de transformaciÃ³n...")
    print(f"ðŸ”— Conectando a la base de datos: {DB_URL}")

    try:
        engine = create_engine(DB_URL)
        query_results = run_queries(engine)

        print("âœ… Transformaciones ejecutadas. Resultados:")
        for name, df in query_results.items():
            print(f"\nðŸ” Resultado para: {name}")
            print(df.head())
    except Exception as e:
        print(f"âŒ Error en transform_task: {e}")
        raise

default_args = {
    "owner": "airflow",
    "start_date": datetime(2024, 1, 1),
    "retries": 1,
}

with DAG(
    dag_id="etl_olist_dag",
    default_args=default_args,
    schedule_interval=None,
    catchup=False,
    tags=["olist", "etl"],
) as dag:

    extract_op = PythonOperator(
        task_id="extract",
        python_callable=extract_task,
    )

    load_op = PythonOperator(
        task_id="load",
        python_callable=load_task,
    )

    transform_op = PythonOperator(
        task_id="transform",
        python_callable=transform_task,
    )

    extract_op >> load_op >> transform_op
